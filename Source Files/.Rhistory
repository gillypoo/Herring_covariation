graph TD;
id1((Start))-->id2[Define parameters]
id2-->id3[Initialize: N0=K, t=1]
id3--Threshold Dependent Rule-->id4{Nt less than K/2?}
id4--Yes-->id5[Ht=0]
id4--No-->id6[Ht=r/2*Nt]
id5-->id7[Logistic Growth <br> Model]
id6-->id7
id7-->id12{Was Observation <br> error included?}
id12--Yes-->id13[Set Nt=It]
id12--No-->id14[Use Nt=Nt]
id14-->id8
id13-->id8
id7-->id8{is t less than T?}
id8--Yes-->id4
id8--No-->id9[Return: Nt, Ht]
id9-->id10[Plot time series <br> of H and N]
id10-->id11((Stop))
")
read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/Oregon/Yaquina_Bay.csv")
Yaquina <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/Oregon/Yaquina_Bay.csv")
plot( x=Yaquina$ï..Year, y=Yaquina$Spawning.Biomass..ST.)
plot( x=Yaquina$ï..Year, y=Yaquina$Spawning.Biomass..ST.,
type="l", xlab="Year", ylab="Spawning Biomass (Short Tons)")
PDO <- read.csv(file="C:/Users/jagil/Documents/School/699/Oceanographic Data/PDO Data/3.29.17 PDO Data.csv",
header=TRUE,sep = "")
PDO
Yaquina <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Me playing around/Yaquina_Bay_Proc_dev.csv")
plot( x=Yaquina$ï..Year, y=Yaquina$Spawning.Biomass..ST.,
type="l", xlab="Year", ylab="Spawning Biomass (Short Tons)")
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1)
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1,
type="l")
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1,
type="l", abline=v)
abline?
v
plot?
abline
?plot
?abline
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1,
type="l", abline(h=0))
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1,
type="l", abline(h=0))
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1,
type="l", abline(h=0))
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1,
type="l", abline(h=0.0))
PDO <- read.csv(file="C:/Users/jagil/Documents/School/699/Oceanographic Data/PDO Data/3.29.17 PDO Data.csv",
header=TRUE,sep = "")
Means <- rowMeans(PDO[2:13])
Means
abline(h=0.0)
abline(h=0.0, col=red)
abline(h=0.0, col="red")
Means <- rowMeans(PDO[2:13])
Means
par(mfrow=c(1,1))
par( new=TRUE )
plot( x=PDO$YEAR, y=Means,
type="l", axes=FALSE, bty="n",
xlab="", ylab="", col="blue")
axis( side=4, ylim=c(0,25000), las=1, col="blue")
mtext("Biomass ('000s)", side=4, line = 3, col="blue")
mtext("PDO", side=4, line = 3, col="blue")
legend(1950,250,c("PDO", "Herring"), lty=c(1,1),
lwd=c(2.5,2.5), col=c("red","blue"), bty="n" )
mtext("PDO", side=4, line = 3, col="blue")
mtext("PDO", side=4, line = 1, col="blue")
mtext("PDO", side=4, line = 1.5, col="blue")
plot(x=Yaquina$ï..Year, y=Yaquina$proc_dev_yr1,
type="l" )
abline(h=0.0, col="red")
PDO <- read.csv(file="C:/Users/jagil/Documents/School/699/Oceanographic Data/PDO Data/3.29.17 PDO Data.csv",
header=TRUE,sep = "")
Means <- rowMeans(PDO[2:13])
Means
par(mfrow=c(1,1))
par( new=TRUE )
plot( x=PDO$YEAR, y=Means,
type="l", axes=FALSE, bty="n",
xlab="", ylab="", col="blue")
axis( side=4, ylim=c(0,25000), las=1, col="blue")
mtext("PDO", side=4, line = 1.5, col="blue")
axis( side=4, ylim=c(-2,2), las=1, col="blue")
legend(1990,0.5,c("Herring", "PDO"), lty=c(1,1),
lwd=c(2.5,2.5), col=c("red","blue"), bty="n" )
PDO
plot( x= PDO$YEAR, y=Means, type="l",
xlab="Year", ylab="PDO Index", las=1,
col="red",)
setwd("C:/Users/jagil/Documents/School/699/Herring Data/Source Files")
source("sparky.r")
WAspark <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/3. Washington/WA_Herring_spark.csv")
head(WAspark)
nrow(WAspark)
index <- WAspark[1,] ## but keeping this around as groups
index
WAspark2 <- WAspark[2:45,]
head(WAspark2)
WAspark2 <- WAspark[1:45,]
head(WAspark2)
WAspark2 <- WAspark[2:45,]
head(WAspark2)
WAspark3 <- WAspark2[,-1]
WAspark3
plt.spark( x=c(1:nrow(WAspark3)),y=WAspark3,plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkStats<- t( apply( as.numeric(WAspark3) ,2,calcStats ) )
?t
?apply
sparkStats<- apply( as.numeric(WAspark3) ,2,calcStats )
sparkStats<- apply( as.numeric(unlist(WAspark3) ,2,calcStats )
plt.spark( x=c(1:nrow(WAspark3)),y=WAspark3,plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkStats<- apply( as.numeric(unlist(WAspark3)) , 2, calcStats )
plt.spark( x=c(1:nrow(WAspark3)),y=WAspark3,plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkStats<- lapply(WAspark3, as.numeric) , 2, calcStats )
sparkStats<- t( lapply(WAspark3, as.numeric) , 2, calcStats )
sparkStats<- t( lapply(WAspark3, as.numeric) )
plt.spark( x=c(1:nrow(WAspark3)), y=WAspark3, plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
data.class(WAsparks3)
data.class(WAspark3)
sparkStats<- t( apply(data.matrix(WAspark3, rownames.force = NA)), 2, calcStats)
sparkStats<- t( apply(data.matrix(WAspark3, rownames.force = NA))
plt.spark( x=c(1:nrow(WAspark3)), y=WAspark3, plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkStats<- t( apply(data.matrix(WAspark3, rownames.force = NA))
plt.spark( x=c(1:nrow(WAspark3)), y=WAspark3, plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkStats<- t( apply(data.matrix(WAspark3, rownames.force = NA)))
WAspark <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/3. Washington/WA_Herring_spark.csv")
head(WAspark)
nrow(WAspark)
index <- WAspark[1,] ## but keeping this around as groups
index
WAspark2 <- WAspark[2:45,]
head(WAspark2)
WAspark3 <- WAspark2[,-1]
WAspark3
sparkStats<- t( apply(data.matrix(WAspark3, rownames.force = NA)))
calcStats <- function( x )
{
# Calculates summary statistics.
result <- summary( x )
result
}
calcXaxis <- function( x, labelPct=0.25, plotPct=0.25 )
{
# Extends the range of the x-axis to left and right such
# that the plot occupies plotPct of the range, and the label
# occupies labelPct of the range.
# Check to ensure the percentages are within [0,1].
if ( labelPct < 0 & labelPct > 1 )
{
labelPct <- 0.25
cat( "\ncalcXaxis: labelPct out of bounds - reset.\n" )
}
if ( plotPct  < 0 | plotPct  > 1 )
{
labelPct <- 0.25
cat( "\ncalcXaxis: plotPct out of bounds - reset.\n" )
}
xLim <- range( x,na.rm=TRUE )
xDiff <- xLim[2] - xLim[1]
# Some stupid algebra.
xRange <- xDiff / plotPct
newLim <- xLim
newLim[1] <- xLim[1] - labelPct*xRange
newLim[2] <- xLim[2] + (1.0-labelPct-plotPct)*xRange
newLim
}
panLab <- function( x, y, txt, ... )
{
# Allows text to be placed in plot panel at 0<x<1, 0<y<1.
usr <- par( "usr" )
par( usr=c(0,1,0,1) )
text( x, y, txt, ... )
par( usr=usr )
return( NULL )
}
plt.lines <- function( x, y, xLim,... )
{
# Plot a line graph.
plot( x,y, type="n", axes=F, xlab="", xlim=xLim, ylab="" )
lines( x,y,... )
}
plt.spikes <- function( x, y, xLim,... )
{
# Plot a high density "spike" graph.
plot( x,y,type="n",axes=F, xlab="", xlim=xLim, ylab="" )
lines( x,y,type="h",... )
}
plt.spark <- function( x, y, plotFun, stats, labelPct=0.15, plotPct=0.25,
statPos=NULL,... )
{
# Plots sparklines plots as described by Edward Tufte.
#
# y       : matrix with one column for each sparkline.
# plotFun : the plot function to call (user defined).
# stats   : matrix with statistics for each sparkline.
#           All statistics in the stats matrix are placed on the plot, so
#           subset the columns of this matrix as appropriate.
# labelPct: the percent of the plot x-axis used by the spark labels.
# plotPct : the percent of the plot x-axis used by the spark plot.
# statPos : vector holding [0,1] positions of summary stats (optional).
#           If statPos is not supplied then the statistics are equally
#           spaced in along the x-axis in the space leftover after the
#           labels and the spark line plot.
#
# Note that plot parameters such as "col" and "lwd" or "lty" can be passed
# because of the "..." notation in the function header.
# Number of sparklines and maximum data points each sparkline.
nSpark <- ncol( y )
nPts   <- nrow( y )
# Extract the spark category names from the data, or build them.
dataNames <- dimnames( y )
if ( is.null( dataNames[[2]] ) )
sparkNames <- paste( "Category",c(1:nSpark) )
else
sparkNames <- dataNames[[2]]
# Get the statistics labels.
statNames <- dimnames( stats )
if ( is.null( statNames[[2]] ) )
statNames <- paste( "Stat",c(1:ncol(stats)) )
else
statNames <- statNames[[2]]
# Compute the positions of the statistics.
statPct <- 1.0 - labelPct - plotPct
statPos <- seq( (labelPct+plotPct),1,statPct/length(statNames) )
offset  <- diff(statPos)/2.0
statPos <- statPos[1:(length(statPos)-1)] + offset
# Configure graphics panels to have nSpark rows and one column.
# An additional panel is required for the header.
par( oma=c(1,1,1,1), mar=c(0,0,0,0), mfrow=c(nSpark+1,1) )
# Plot the header graphics panel.
plot( c(0,1),c(0,1), type="n", axes=F, xlab="", ylab="" )
# Output the header.
panLab( labelPct/2,0.5,"Category" )
for ( k in 1:ncol(stats) )
panLab( statPos[k],0.5, adj=0, statNames[k] )
# Loop over the sparklines.
for ( j in 1:nSpark )
{
# Extend the x-axis to allow the spark plot to occupy
# "plotPct" of the range, and the labels "labelPct".
xLim <- calcXaxis( x,labelPct,plotPct )
# Plot the sparkline.  User controls what plot is used by
# passing a function name plotFun= as an argument to plt.spark.
plotFun( x,y[,j],xLim,...)
# Sparkline main row labels.
panLab( 0.01, 0.5, adj=0, sparkNames[j] )
# Make summary text of stats.
for ( k in 1:ncol(stats) )
panLab( statPos[k],0.5, adj=0, round(stats[j,k],3 ) )
}
par( mfrow=c(1,1) )
}
nData <- 1000
sparkData <- matrix( rnorm( nData, mean=1, sd=1 ), nrow=nData/20, ncol=20 )
dimnames( sparkData ) <- list( NULL,paste( "Spark",c(1:ncol(sparkData)) ) )
sparkStats <- t( apply( sparkData,2,calcStats ) )
plt.spark( x=c(1:nrow(sparkData)),y=sparkData,plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
cat( "\nPress Enter to continue\n" )
scan()
sparkStats[,c("Min.","Median","Mean","Max.")],
col="blue", plotPct=0.35 )
plt.spark( x=c(1:nrow(sparkData)),y=sparkData,plt.spikes,
sparkStats[,c("Min.","Median","Mean","Max.")],
col="blue", plotPct=0.35 )
cat( "\nPress Enter to continue\n" )
scan()
sparkStats[,c("Min.","Mean","Max.")],
cex=2.0, col="green", lty=3, lwd=2,
labelPct=0.1, plotPct=0.3 )
plt.spark( x=c(1:nrow(sparkData)),y=sparkData,plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
cex=2.0, col="green", lty=3, lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkStats<- t( apply(data.matrix(WAspark3, rownames.force = NA)))
plt.spark( x=c(1:nrow(WAspark3)), y=WAspark3, plt.lines,
sparkStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkWAStats <- t( apply( WAspark3,2,calcStats ) )
plt.spark( x=c(1:nrow(WAspark3)), y=WAspark3, plt.lines,
sparkWAStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkWAStats <- t( apply( WAspark3,2,calcStats ) )
plt.spark( x=c(1:nrow(WAspark3)), y=WAspark3, plt.lines,
sparkWAStats[,c("Min.","Mean","Max.")],
col="red", lwd=2,
labelPct=0.1, plotPct=0.3 )
sparkWAStats
sparkWAStats <- t( apply( as.numeric(WAspark3),2,calcStats ) )
source('~/.active-rstudio-document', echo=TRUE)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/ggplot2_sparklines.R', echo=TRUE)
install.packages(ggthemes)
install.packages("https://cran.r-project.org/package=ggthemes")
install.packages("C:/Users/jagil/Downloads/ggthemes_3.4.0.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/jagil/Downloads/dplyr_0.5.0.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/jagil/Downloads/RCurl_1.95-4.8.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/jagil/Downloads/reshape_0.8.6.zip", repos = NULL, type = "win.binary")
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/ggplot2_sparklines.R', echo=TRUE)
source('C:/Users/jagil/Documents/School/699/Herring Data/Me playing around/sparkplots.r')
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/ggplot2_sparklines.R', echo=TRUE)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(reshape)
library(RCurl)
dd <- read.csv(text = getURL("https://gist.githubusercontent.com/GeekOnAcid/da022affd36310c96cd4/raw/9c2ac2b033979fcf14a8d9b2e3e390a4bcc6f0e3/us_nr_of_crimes_1960_2014.csv"))
d <- melt(dd, id="Year")
names(d) <- c("Year","Crime.Type","Crime.Rate")
d$Crime.Rate <- round(d$Crime.Rate,0)
mins <- group_by(d, Crime.Type) %>% slice(which.min(Crime.Rate))
maxs <- group_by(d, Crime.Type) %>% slice(which.max(Crime.Rate))
ends <- group_by(d, Crime.Type) %>% filter(Year == max(Year))
quarts <- d %>% group_by(Crime.Type) %>%
summarize(quart1 = quantile(Crime.Rate, 0.25),
quart2 = quantile(Crime.Rate, 0.75)) %>%
right_join(d)
pdf("sparklines_ggplot.pdf", height=10, width=8)
ggplot(d, aes(x=Year, y=Crime.Rate)) +
facet_grid(Crime.Type ~ ., scales = "free_y") +
geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), fill = 'grey90') +
geom_line(size=0.3) +
geom_point(data = mins, col = 'red') +
geom_point(data = maxs, col = 'blue') +
geom_text(data = mins, aes(label = Crime.Rate), vjust = -1) +
geom_text(data = maxs, aes(label = Crime.Rate), vjust = 2.5) +
geom_text(data = ends, aes(label = Crime.Rate), hjust = 0, nudge_x = 1) +
geom_text(data = ends, aes(label = Crime.Type), hjust = 0, nudge_x = 5) +
expand_limits(x = max(d$Year) + (0.25 * (max(d$Year) - min(d$Year)))) +
scale_x_continuous(breaks = seq(1960, 2010, 10)) +
scale_y_continuous(expand = c(0.1, 0)) +
theme_tufte(base_size = 15, base_family = "Helvetica") +
theme(axis.title=element_blank(), axis.text.y = element_blank(),
axis.ticks = element_blank(), strip.text = element_blank())
dev.off()
rm(list=ls())
rm(list=ls())
?melt
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/3. Washington/WA_Herring.csv",
header = TRUE, sep=",")
WA2 <- melt(WA, id="Year")
WA
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/3. Washington/WA_Herring_spark.csv",
header = TRUE, sep=",")
WA
WA <- WA[-1,]
WA
WA2 <- melt(WA, id="ï..")
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/ggplot2_sparklines.R', echo=TRUE)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/ggplot2_sparklines.R', echo=TRUE)
names(d)
d
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/3. Washington/WA_ggplot2_Spark_SOUTH.csv",
header = TRUE, sep=",")
WA
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Data From Others/3. Washington/WA_ggplot2_Spark_SOUTH.csv",
header = TRUE, sep=",")
head(WA)
tail(WA)
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Figures/WA_ggplot2_SOUTHONLY.csv",
header = TRUE, sep=",")
WA
head(WA)
WA <- WA[,1:3]
WA
WA2 <- melt(WA, id="ï..YEAR")
WA2
names(WA) <- c("Year","Stock","Short.tons")
WA$Short.tons <- round(wA$Short.tons,0)
WA$Short.tons <- round(WA$Short.tons,0)
head(WA)
mins <- group_by(WA, Stock) %>% slice(which.min(Short.tons))
maxs <- group_by(WA, Stock) %>% slice(which.max(Short.tons))
ends <- group_by(WA, Stock) %>% filter(Year == max(Year))
quarts <- WA %>% group_by(Stock)) %>%
summarize(quart1 = quantile(Short.tons, 0.25),
quart2 = quantile(Short.tons, 0.75)) %>%
right_join(WA)
pdf("sparklines_ggplot_WASouth.pdf", height=10, width=8)
ggplot(WA, aes(x=Year, y=Short.tons)) +
facet_grid(Stock ~ ., scales = "free_y") +
geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), fill = 'grey90') +
geom_line(size=0.3) +
geom_point(data = mins, col = 'red') +
geom_point(data = maxs, col = 'blue') +
geom_text(data = mins, aes(label = Short.tons), vjust = -1) +
geom_text(data = maxs, aes(label = Short.tons), vjust = 2.5) +
geom_text(data = ends, aes(label = Short.tons), hjust = 0, nudge_x = 1) +
geom_text(data = ends, aes(label = Short.tons), hjust = 0, nudge_x = 5) +
expand_limits(x = max(d$Year) + (0.25 * (max(d$Year) - min(d$Year)))) +
scale_x_continuous(breaks = seq(1960, 2010, 10)) +
scale_y_continuous(expand = c(0.1, 0)) +
theme_tufte(base_size = 15, base_family = "Helvetica") +
theme(axis.title=element_blank(), axis.text.y = element_blank(),
axis.ticks = element_blank(), strip.text = element_blank())
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
WA2 <- melt(WA, id="ï..YEAR")
WA2 <- melt(WA, id="YEAR")
WA <- WA[,1:3]
WA
WA2 <- melt(WA, id="Year")
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
head(WA2)
head(WA)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
WA2 <- melt(WA, id="ï..YEAR")
rm(list=ls())
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Figures/WA_ggplot2_SOUTHONLY.csv",
header = TRUE, sep=",")
WA
head(WA)
WA <- WA[,1:3]
head(WA)
WA2 <- melt(WA, id="ï..YEAR")
names(WA) <- c("Year","Stock","Short.tons")
WA$Short.tons <- round(WA$Short.tons,0)
mins <- group_by(WA, Stock) %>% slice(which.min(Short.tons))
maxs <- group_by(WA, Stock) %>% slice(which.max(Short.tons))
ends <- group_by(WA, Stock) %>% filter(Year == max(Year))
quarts <- WA %>% group_by(Stock) %>%
summarize(quart1 = quantile(Short.tons, 0.25),
quart2 = quantile(Short.tons, 0.75),na.rm=T) %>%
right_join(WA)
pdf("sparklines_ggplot_WASouth.pdf", height=10, width=8)
quarts <- WA %>% group_by(Stock) %>%
summarize(quart1 = quantile(Short.tons, 0.25),
quart2 = quantile(Short.tons, 0.75),
na.rm=T) %>%
right_join(WA)
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Figures/WA_ggplot2_SOUTHONLY.csv",
header = TRUE, sep=",")
WA <- WA[,1:3]
names(WA) <- c("Year","Stock","Short.tons")
WA$Short.tons <- round(WA$Short.tons,0)
mins <- group_by(WA, Stock) %>% slice(which.min(Short.tons))
maxs <- group_by(WA, Stock) %>% slice(which.max(Short.tons))
ends <- group_by(WA, Stock) %>% filter(Year == max(Year))
quarts <- WA %>% group_by(Stock) %>%
summarize(quart1 = quantile(Short.tons, 0.25),
quart2 = quantile(Short.tons, 0.75),
na.rm=T) %>%
right_join(WA)
pdf("sparklines_ggplot_WASouth.pdf", height=10, width=8)
ggplot(WA, aes(x=Year, y=Short.tons)) +
facet_grid(Stock ~ ., scales = "free_y") +
geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), fill = 'grey90') +
geom_line(size=0.3) +
geom_point(data = mins, col = 'red') +
geom_point(data = maxs, col = 'blue') +
geom_text(data = mins, aes(label = Short.tons), vjust = -1) +
geom_text(data = maxs, aes(label = Short.tons), vjust = 2.5) +
geom_text(data = ends, aes(label = Short.tons), hjust = 0, nudge_x = 1) +
geom_text(data = ends, aes(label = Short.tons), hjust = 0, nudge_x = 5) +
expand_limits(x = max(d$Year) + (0.25 * (max(d$Year) - min(d$Year)))) +
scale_x_continuous(breaks = seq(1960, 2010, 10)) +
scale_y_continuous(expand = c(0.1, 0)) +
theme_tufte(base_size = 15, base_family = "Helvetica") +
theme(axis.title=element_blank(), axis.text.y = element_blank(),
axis.ticks = element_blank(), strip.text = element_blank())
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
WA2 <- melt(WA, id="ï..YEAR")
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Figures/WA_ggplot2_SOUTHONLY.csv",
header = TRUE, sep=",")
WA <- WA[,1:3]
head(WA)
WA2 <- melt(WA, id="ï..YEAR")
names(WA2) <- c("Year","Stock","Short.tons")
head(WA2)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/ggplot2_sparklines.R', echo=TRUE)
head(d)
head(dd)
names(WA) <- c("Year","Stock","Short.tons")
head(WA)
names(WAs) <- c("Year","Stock","Short.tons")
WA <- read.csv("C:/Users/jagil/Documents/School/699/Herring Data/Figures/WA_ggplot2_SOUTHONLY.csv",
header = TRUE, sep=",")
head(WA)
WAs <- WA[,1:3]
head(WAs)
names(WAs) <- c("Year","Stock","Short.tons")
head(WAs)
names(WAs) <- c("Year","Stock","Biomass")
head(WAs)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
source('C:/Users/jagil/Documents/School/699/Herring Data/Figures/WAsouth_ggplot2_sparklines.R', echo=TRUE)
